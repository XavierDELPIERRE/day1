{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env :  projetday1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ISR.models import RRDN\n",
    "\n",
    "print (\"Env : \", os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "datapath = '/media/xav/data/pday1/'\n",
    "img = Image.open(datapath+'sample/téléchargement.jpeg')\n",
    "lr_img = np.array(img.convert(\"RGB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nfrom PIL import Image\\n\\n#img = Image.open(\\'/home/xav/Images/Capture d’écran de 2020-08-17 19-21-21.png\\' )\\n\\nimg = Image.open(datapath+\\'sample/téléchargement.jpeg\\')\\nlr_img = np.array(img.convert(\"RGB\"))\\nprint(lr_img.shape)\\n#Image.fromarray(lr_img)\\n#img = Image.open(datapath+\\'sample/sam.png\\' )\\n\\n#lr_img = np.array(img)\\n#print(lr_img.shape)\\n\\nfrom ISR.models import RDN\\n\\nrdn = RDN(arch_params={\\'C\\':6, \\'D\\':20, \\'G\\':64, \\'G0\\':64, \\'x\\':2})\\nrdn.model.load_weights(datapath+ \\'weights/rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5\\')\\n#print(np.concatenate((lr_img,)*2, axis=-1).shape)\\n#Image.fromarray(np.concatenate((lr_img,)*3, axis=-1))\\n\\n#rdn = RDN(weights=\\'psnr-small\\')\\nsr_img = rdn.predict(lr_img, by_patch_of_size=50)\\n\\n#sr_img = rdn.predict(lr_img)\\nImage.fromarray(sr_img)\\n\\n#sr_img = model.predict(image, by_patch_of_size=50)\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#img = Image.open('/home/xav/Images/Capture d’écran de 2020-08-17 19-21-21.png' )\n",
    "\n",
    "img = Image.open(datapath+'sample/téléchargement.jpeg')\n",
    "lr_img = np.array(img.convert(\"RGB\"))\n",
    "print(lr_img.shape)\n",
    "#Image.fromarray(lr_img)\n",
    "#img = Image.open(datapath+'sample/sam.png' )\n",
    "\n",
    "#lr_img = np.array(img)\n",
    "#print(lr_img.shape)\n",
    "\n",
    "from ISR.models import RDN\n",
    "\n",
    "rdn = RDN(arch_params={'C':6, 'D':20, 'G':64, 'G0':64, 'x':2})\n",
    "rdn.model.load_weights(datapath+ 'weights/rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5')\n",
    "#print(np.concatenate((lr_img,)*2, axis=-1).shape)\n",
    "#Image.fromarray(np.concatenate((lr_img,)*3, axis=-1))\n",
    "\n",
    "#rdn = RDN(weights='psnr-small')\n",
    "sr_img = rdn.predict(lr_img, by_patch_of_size=50)\n",
    "\n",
    "#sr_img = rdn.predict(lr_img)\n",
    "Image.fromarray(sr_img)\n",
    "\n",
    "#sr_img = model.predict(image, by_patch_of_size=50)\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrdn = RDN(arch_params={'C': 3, 'D':10, 'G':64, 'G0':64, 'x':2})\\nrdn.model.load_weights(datapath+ 'weights/rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5')\\nsr_img = rdn.predict(lr_img, by_patch_of_size=50)\\nImage.fromarray(sr_img)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rdn = RDN(arch_params={'C': 3, 'D':10, 'G':64, 'G0':64, 'x':2})\n",
    "rdn.model.load_weights(datapath+ 'weights/rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5')\n",
    "sr_img = rdn.predict(lr_img, by_patch_of_size=50)\n",
    "Image.fromarray(sr_img)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISR.models import RRDN\n",
    "from ISR.models import Discriminator\n",
    "from ISR.models import Cut_VGG19\n",
    "\n",
    "lr_train_patch_size = 40\n",
    "layers_to_extract = [5, 9]\n",
    "scale = 2\n",
    "hr_train_patch_size = lr_train_patch_size * scale\n",
    "\n",
    "rrdn  = RRDN(arch_params={'C':4, 'D':3, 'G':64, 'G0':64, 'T':10, 'x':scale}, patch_size=lr_train_patch_size)\n",
    "f_ext = Cut_VGG19(patch_size=hr_train_patch_size, layers_to_extract=layers_to_extract)\n",
    "discr = Discriminator(patch_size=hr_train_patch_size, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISR.train import Trainer\n",
    "\n",
    "loss_weights = {\n",
    "  'generator': 0.0,\n",
    "  'feature_extractor': 0.0833,\n",
    "  'discriminator': 0.01\n",
    "}\n",
    "losses = {\n",
    "  'generator': 'mae',\n",
    "  'feature_extractor': 'mse',\n",
    "  'discriminator': 'binary_crossentropy'\n",
    "}\n",
    "\n",
    "log_dirs = {'logs': './logs', 'weights': './weights'}\n",
    "\n",
    "learning_rate = {'initial_value': 0.0004, 'decay_factor': 0.5, 'decay_frequency': 30}\n",
    "\n",
    "flatness = {'min': 0.0, 'max': 0.15, 'increase': 0.01, 'increase_frequency': 5}\n",
    "\n",
    "adam_optimizer = {'beta1': 0.9, 'beta2': 0.999, 'epsilon': None}\n",
    "\n",
    "trainer = Trainer(\n",
    "    generator=rrdn,\n",
    "    discriminator=discr,\n",
    "    feature_extractor=f_ext,\n",
    "    lr_train_dir=datapath+'div2k/DIV2K_train_LR_bicubic/X2/',\n",
    "    hr_train_dir=datapath+'div2k/DIV2K_train_HR/',\n",
    "    lr_valid_dir=datapath+'div2k/DIV2K_train_LR_bicubic/X2/',\n",
    "    hr_valid_dir=datapath+'div2k/DIV2K_train_HR/',\n",
    "    loss_weights=loss_weights,\n",
    "    losses=losses,\n",
    "    learning_rate=learning_rate,\n",
    "    flatness=flatness,\n",
    "    log_dirs=log_dirs,\n",
    "    adam_optimizer=adam_optimizer,\n",
    "    metrics={'generator': 'PSNR_Y'},\n",
    "    dataname='div2k',\n",
    "    weights_generator=None,\n",
    "    weights_discriminator=None,\n",
    "    n_validation=40,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training details:\n",
      "  training_parameters: \n",
      "    lr_train_dir: /media/xav/data/pday1/div2k/DIV2K_train_LR_bicubic/X2/\n",
      "    hr_train_dir: /media/xav/data/pday1/div2k/DIV2K_train_HR/\n",
      "    lr_valid_dir: /media/xav/data/pday1/div2k/DIV2K_train_LR_bicubic/X2/\n",
      "    hr_valid_dir: /media/xav/data/pday1/div2k/DIV2K_train_HR/\n",
      "    loss_weights: {'generator': 0.0, 'feature_extractor': 0.0833, 'discriminator': 0.01}\n",
      "    log_dirs: {'logs': './logs', 'weights': './weights'}\n",
      "    fallback_save_every_n_epochs: 2\n",
      "    dataname: div2k\n",
      "    n_validation: 40\n",
      "    flatness: {'min': 0.0, 'max': 0.15, 'increase': 0.01, 'increase_frequency': 5}\n",
      "    learning_rate: {'initial_value': 0.0004, 'decay_factor': 0.5, 'decay_frequency': 30}\n",
      "    adam_optimizer: {'beta1': 0.9, 'beta2': 0.999, 'epsilon': None}\n",
      "    losses: {'generator': 'mae', 'feature_extractor': 'mse', 'discriminator': 'binary_crossentropy'}\n",
      "    metrics: {'generator': <function PSNR_Y at 0x7f9ac42210e0>}\n",
      "    lr_patch_size: 40\n",
      "    steps_per_epoch: 20\n",
      "    batch_size: 4\n",
      "    starting_epoch: 0\n",
      "  generator: \n",
      "    name: rrdn\n",
      "    parameters: {'C': 4, 'D': 3, 'G': 64, 'G0': 64, 'T': 10, 'x': 2}\n",
      "    weights_generator: None\n",
      "  discriminator: \n",
      "    name: srgan-large\n",
      "    weights_discriminator: None\n",
      "  feature_extractor: \n",
      "    name: vgg19\n",
      "    layers: [5, 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... can't pickle _thread.RLock objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "Current learning rate: 0.00039999998989515007\n",
      "100%|██████████| 20/20 [00:16<00:00,  1.22it/s]\n",
      "Epoch 0 took       16.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "160/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 4s 27ms/sample - loss: 0.8926 - generator_loss: 0.3968 - discriminator_loss: 0.0078 - feature_extractor_loss: 3.3594 - feature_extractor_1_loss: 15.5927 - generator_PSNR_Y: 8.6102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'val_loss': 0.789432785846293, 'val_generator_loss': 0.39677048, 'val_discriminator_loss': 0.0077741877, 'val_feature_extractor_loss': 3.359367, 'val_feature_extractor_1_loss': 15.592732, 'val_generator_PSNR_Y': 8.610157, 'train_d_real_loss': 0.062099487, 'train_d_real_accuracy': 1.0, 'train_d_fake_loss': 0.119073145, 'train_d_fake_accuracy': 0.99875, 'train_loss': 1.1911682, 'train_generator_loss': 0.42985448, 'train_discriminator_loss': 0.0056302827, 'train_feature_extractor_loss': 5.3516927, 'train_feature_extractor_1_loss': 23.246431, 'train_generator_PSNR_Y': 7.6335683}\n",
      "val_generator_PSNR_Y improved from       -inf to    8.61016\n",
      "Saving weights\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=1,\n",
    "    steps_per_epoch=20,\n",
    "    batch_size=4,\n",
    "    monitored_metrics={'val_generator_PSNR_Y': 'max'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\r\n"
     ]
    }
   ],
   "source": [
    "#pred\n",
    "!echo 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected LR_input to have shape (40, 40, 3) but got array with shape (44, 44, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-77f44c79f132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#sr_img = rrdn.predict(lr_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msr_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrrdn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_patch_of_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projetday1/lib/python3.7/site-packages/ISR/models/imagemodel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_image_array, by_patch_of_size, batch_size, padding_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# return patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mcollect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projetday1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projetday1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 715\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    716\u001b[0m     return predict_loop(\n\u001b[1;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projetday1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projetday1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected LR_input to have shape (40, 40, 3) but got array with shape (44, 44, 3)"
     ]
    }
   ],
   "source": [
    "#sr_img = rrdn.predict(lr_img)\n",
    "sr_img = rrdn.predict(lr_img, by_patch_of_size=40)\n",
    "\n",
    "Image.fromarray(sr_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:projetday1]",
   "language": "python",
   "name": "conda-env-projetday1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
